{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdII/OWrMOAy+OOreXiORP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Auroraleone/MLDLproject-/blob/main/Ensemple.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ENSEMBLE##\n"
      ],
      "metadata": {
        "id": "KxzNuDgEb3RY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## MIOU.py ##\n",
        "\n",
        "def calculate_iou(true_int, pred_int):\n",
        "    lower_true = true_int[0]\n",
        "    upper_true = true_int[1]\n",
        "    lower_pred = pred_int[0]\n",
        "    upper_pred = pred_int[1]\n",
        "\n",
        "    if upper_true < lower_pred or lower_true > upper_pred:\n",
        "        return 0.0\n",
        "    else:\n",
        "        intersection = max(0, min(upper_true, upper_pred) - max(lower_true, lower_pred))\n",
        "        union = max(upper_true, upper_pred) - min(lower_true, lower_pred)\n",
        "        return intersection / union\n",
        "\n",
        "\n",
        "def calculate_miou(true_int, pred_ints):\n",
        "    ious = [calculate_iou(true_int, pred_int) for pred_int in pred_ints]\n",
        "    return sum(ious) / len(pred_ints)\n"
      ],
      "metadata": {
        "id": "NQwxIx-ib9as"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## update_json_with_intervals.py ##\n",
        "\n",
        "import json\n",
        "\n",
        "\n",
        "def update_json_with_intervals(json_file_path, intervals_list):\n",
        "    with open(json_file_path, 'r') as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    if len(data['results']) < len(intervals_list):\n",
        "        print(\"The numer of lists does not match the results in the JSON file\")\n",
        "        return\n",
        "\n",
        "    for i in range(min(len(data['results']), len(intervals_list))):\n",
        "        if len(intervals_list[i]) != 5:\n",
        "            print(f\"List of intervals in position {i} does not have length 5.\")\n",
        "            return\n",
        "        data['results'][i]['predicted_times'] = intervals_list[i]\n",
        "\n",
        "    with open(json_file_path, 'w') as file:\n",
        "        json.dump(data, file, indent=4)\n",
        "    print(f\"File JSON updated and saved in {json_file_path}\")\n"
      ],
      "metadata": {
        "id": "jKw62ETzcIHY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## val_to_csv.py ##\n",
        "\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def read_file_json(file_name):\n",
        "    with open(file_name, 'r', encoding='utf-8') as file:\n",
        "        data = json.load(file)\n",
        "    return data\n",
        "\n",
        "\n",
        "def create_list_of_dictionaries(data):\n",
        "    list_of_dictionaries = []\n",
        "    for key, value in data.items():\n",
        "        dictionary = {\n",
        "            'clip_uid': key,\n",
        "            'fps': value['fps'],\n",
        "            'num_frames': value['num_frames'],\n",
        "            'timestamps': value['timestamps'],\n",
        "            'exact_times': value['exact_times'],\n",
        "            'sentences': value['sentences'],\n",
        "            'annotation_uids': value['annotation_uids'],\n",
        "            'query_idx': value['query_idx']\n",
        "        }\n",
        "        list_of_dictionaries.append(dictionary)\n",
        "    return list_of_dictionaries\n",
        "\n",
        "\n",
        "def from_dict_to_df(dict):\n",
        "    df = pd.DataFrame({\n",
        "        'clip_uid': [dict['clip_uid']] * len(dict['timestamps']),\n",
        "        'fps': [dict['fps']] * len(dict['timestamps']),\n",
        "        'num_frames': [dict['num_frames']] * len(dict['timestamps']),\n",
        "        'timestamp': dict['timestamps'],\n",
        "        'exact_time': dict['exact_times'],\n",
        "        'sentences': dict['sentences'],\n",
        "        'annotation_uids': dict['annotation_uids'],\n",
        "        'query_idx': dict['query_idx']\n",
        "    })\n",
        "    return df\n",
        "\n",
        "json_file_name = 'val.json'\n",
        "data = read_file_json(json_file_name)\n",
        "list_of_dictionaries = create_list_of_dictionaries(data)\n",
        "\n",
        "pd.set_option('display.max_columns', None)\n",
        "\n",
        "df_list = []\n",
        "for i in range(len(list_of_dictionaries)):\n",
        "    df_list.append(from_dict_to_df(list_of_dictionaries[i]))\n",
        "\n",
        "df_concatenated = pd.concat(df_list, ignore_index=True)\n",
        "\n",
        "print(df_concatenated)\n",
        "\n",
        "file_name = 'VALIDATION.csv'\n",
        "df_concatenated.to_csv(file_name, index=False)\n",
        "\n",
        "print(f\"DataFrame salved in '{file_name}'.\")\n"
      ],
      "metadata": {
        "id": "vAQxhvYWcMIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## vsl_pred_to_csv.py ##\n",
        "\n",
        "def json_to_csv(file_path):\n",
        "\n",
        "    import pandas as pd\n",
        "    import os\n",
        "\n",
        "    df = pd.read_json(file_path)\n",
        "\n",
        "    df['clip_uid'] = df['results'].apply(lambda x: x['clip_uid'])\n",
        "    df['annotation_uid'] = df['results'].apply(lambda x: x['annotation_uid'])\n",
        "    df['query_idx'] = df['results'].apply(lambda x: x['query_idx'])\n",
        "\n",
        "    predicted_times = df['results'].apply(lambda x: x['predicted_times'])\n",
        "    for i in range(5):\n",
        "        df[f'predicted_times_{i}'] = predicted_times.apply(lambda x: x[i] if i < len(x) else None)\n",
        "\n",
        "    final_df = df[['clip_uid', 'annotation_uid', 'query_idx',\n",
        "                   'predicted_times_0', 'predicted_times_1',\n",
        "                   'predicted_times_2', 'predicted_times_3',\n",
        "                   'predicted_times_4']]\n",
        "\n",
        "    file_name = os.path.splitext(os.path.basename(file_path))[0]\n",
        "\n",
        "    csv_file_path = f'{file_name}.csv'\n",
        "\n",
        "    final_df.to_csv(csv_file_path, index=False)\n",
        "\n",
        "\n",
        "    return csv_file_path\n"
      ],
      "metadata": {
        "id": "3sNIJk2ccP9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Ensemble.py ##\n",
        "\n",
        "import statistics\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "from MIoU import calculate_iou, calculate_miou\n",
        "from vsl_pred_to_csv import json_to_csv\n",
        "from update_json_with_intervals import update_json_with_intervals\n",
        "import re\n",
        "import csv\n",
        "\n",
        "\n",
        "## Extraction of the list of true intervals ##\n",
        "\n",
        "def extract_true_intervals(file_path):\n",
        "    # Load the CSV file into a pandas DataFrame\n",
        "    try:\n",
        "        df = pd.read_csv(file_path)\n",
        "    except FileNotFoundError:\n",
        "        print(f\"File '{file_path}' not found.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading the CSV file: {str(e)}\")\n",
        "\n",
        "    # Verify that the DataFrame has been loaded correctly\n",
        "    if 'exact_time' in df.columns:\n",
        "        exact_times_column = df['exact_time']\n",
        "        # print(exact_times_column)\n",
        "    else:\n",
        "        print(\"The column 'exact_time' is not present in the DataFrame.\")\n",
        "\n",
        "    ## Convert the list of strings \"[x, y]\" into a list of lists ##\n",
        "    import json\n",
        "\n",
        "    # Convert strings to lists of floats\n",
        "    exact_times_column = [json.loads(s) for s in exact_times_column]\n",
        "\n",
        "    return exact_times_column\n",
        "\n",
        "\n",
        "\n",
        "########################################################################################################################\n",
        "\n",
        "def extract_5_predictions(val_pred_csv):\n",
        "    # Load the CSV file into a pandas DataFrame\n",
        "    try:\n",
        "        df = pd.read_csv(val_pred_csv)  # Replace 'nome_file.csv' with the correct path to your CSV file\n",
        "    except FileNotFoundError:\n",
        "        print(\"File not found.\")\n",
        "        exit()\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading the CSV file: {str(e)}\")\n",
        "        exit()\n",
        "\n",
        "    # Ensure the columns exist in the DataFrame\n",
        "    columns_to_extract = ['predicted_times_0', 'predicted_times_1', 'predicted_times_2', 'predicted_times_3',\n",
        "                          'predicted_times_4']\n",
        "    for col in columns_to_extract:\n",
        "        if col not in df.columns:\n",
        "            print(f\"The column '{col}' does not exist in the DataFrame.\")\n",
        "            exit()\n",
        "\n",
        "    # Extract the columns as separate lists\n",
        "    predicted_times_0 = df['predicted_times_0'].tolist()\n",
        "    predicted_times_1 = df['predicted_times_1'].tolist()\n",
        "    predicted_times_2 = df['predicted_times_2'].tolist()\n",
        "    predicted_times_3 = df['predicted_times_3'].tolist()\n",
        "    predicted_times_4 = df['predicted_times_4'].tolist()\n",
        "\n",
        "    ## Convert the list of strings \"[x, y]\" into a list of lists ##\n",
        "    ## 0 ##\n",
        "    predicted_times_0 = [json.loads(s) for s in predicted_times_0]\n",
        "\n",
        "    ## 1 ##\n",
        "    predicted_times_1 = [json.loads(s) for s in predicted_times_1]\n",
        "\n",
        "    ## 2 ##\n",
        "    predicted_times_2 = [json.loads(s) for s in predicted_times_2]\n",
        "\n",
        "    ## 3 ##\n",
        "    predicted_times_3 = [json.loads(s) for s in predicted_times_3]\n",
        "\n",
        "    ## 4 ##\n",
        "    predicted_times_4 = [json.loads(s) for s in predicted_times_4]\n",
        "\n",
        "    return predicted_times_0, predicted_times_1, predicted_times_2, predicted_times_3, predicted_times_4\n",
        "\n",
        "\n",
        "########################################################################################################################\n",
        "\n",
        "\n",
        "def ensemble(num_mod=10, split=0.67, rank=1, inter=0.3, miou_choice=2, weight_choice=\"rank_inter\",\n",
        "             influent_threshold=0.67, power=1, max_weight=False, comparison=\"all\"):\n",
        "    \"\"\"\n",
        "    Function to perform ensemble of models.\n",
        "\n",
        "    Parameters:\n",
        "    num_mod (int): Number of models to ensemble.\n",
        "    epochs (int): Number of epochs for training.\n",
        "    num_ep (int): Number of epochs to consider.\n",
        "    split (float): Split ratio for training and test.\n",
        "    rank (int): Rank in the Rank/Intersection measure.\n",
        "    inter (float): Threshold of IoU considered between intervals.\n",
        "    miou_choice (int): Choice of the mean Intersection over Union (mIoU) considered.\n",
        "    weight_choice (str): Measure for choosing weights.\n",
        "    influent_threshold (float): Threshold for considering influential models.\n",
        "    power (int): Power parameter for weighting.\n",
        "    max_weight (bool): Whether to use the maximum weight as reference or not.\n",
        "    comparison (str): Comparison with the presumed best or with the actual (aggregated) best.\n",
        "\n",
        "    Returns:\n",
        "    The evaluation of the model specified in the \"comparison\" input, the evalutaion of the ensemble and its predictions.\n",
        "    \"\"\"\n",
        "\n",
        "    ########################################################################################################################\n",
        "    ## Cutting non-influential models for ensemble and voting ##\n",
        "\n",
        "    def cut_below_threshold(lista, threshold=0.67):\n",
        "        \"\"\"\n",
        "        Cuts values in the list that are below a certain threshold relative to the maximum value.\n",
        "\n",
        "        Parameters:\n",
        "        lista: List of numerical values.\n",
        "        threshold: A float representing the fraction of the maximum value below which items are set to 0.\n",
        "\n",
        "        Returns:\n",
        "        A new list where values below the threshold * max_value are set to 0.\n",
        "        \"\"\"\n",
        "        max_value = max(lista)  # Find the maximum value in the list\n",
        "        threshold_value = threshold * max_value  # Calculate the threshold value as a fraction of the max value\n",
        "        return [x if x >= threshold_value else 0 for x in lista]  # Replace values below the threshold with 0\n",
        "\n",
        "    ########################################################################################################################\n",
        "    ## Function that evaluates if the intersection of two intervals is non-empty or if it is generally smaller than a certain threshold ##\n",
        "\n",
        "    def non_empty_intersection(interval1, interval2, threshold=0.3):\n",
        "        \"\"\"\n",
        "        Determines if the intersection of two two-dimensional intervals is non-empty and if\n",
        "        the ratio between the intersection and the union is greater than a certain threshold.\n",
        "\n",
        "        Parameters:\n",
        "        interval1: List with a pair of coordinates [x1_min, x1_max]\n",
        "        interval2: List with a pair of coordinates [x2_min, x2_max]\n",
        "        threshold: The threshold below which the function returns 0\n",
        "\n",
        "        Returns:\n",
        "        1 if the ratio between intersection and union is greater than the threshold, otherwise 0.\n",
        "        \"\"\"\n",
        "\n",
        "        x1_min, x1_max = interval1[0], interval1[1]\n",
        "        x2_min, x2_max = interval2[0], interval2[1]\n",
        "\n",
        "        # Calculate the intersection limits\n",
        "        intersection_min = max(x1_min, x2_min)\n",
        "        intersection_max = min(x1_max, x2_max)\n",
        "\n",
        "        # If there is no intersection, return 0\n",
        "        if intersection_min >= intersection_max:\n",
        "            return 0\n",
        "\n",
        "        # Calculate the length of the intersection and the union\n",
        "        intersection_length = intersection_max - intersection_min\n",
        "        union_length = (x1_max - x1_min) + (x2_max - x2_min) - intersection_length\n",
        "\n",
        "        # Calculate the intersection/union ratio\n",
        "        ratio = intersection_length / union_length\n",
        "\n",
        "        # Return 1 if the ratio is greater than the threshold, otherwise 0\n",
        "        if ratio > threshold:\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "\n",
        "    #########################################################################################################################\n",
        "    ## Function that determines the representative for a given interval through a voting system ##\n",
        "\n",
        "    def determine_reference(interval_list, weight_list, inter_threshold):\n",
        "        \"\"\"\n",
        "        Determines the representative for a given interval through a voting system.\n",
        "\n",
        "        Parameters:\n",
        "        interval_list: List of intervals.\n",
        "        weight_list: List of weights corresponding to the intervals.\n",
        "        inter_threshold: The threshold for determining if intervals intersect.\n",
        "\n",
        "        Returns:\n",
        "        A list where each entry represents the number of votes each interval received.\n",
        "        \"\"\"\n",
        "        votes = []  # List to store the number of votes for each interval\n",
        "        non_influential_sets = {i for i, weight in enumerate(weight_list) if\n",
        "                                weight == 0}  # Indices of non-influential sets\n",
        "\n",
        "        for idx1, interval1 in enumerate(interval_list):\n",
        "            if idx1 in non_influential_sets:  # Skip non-influential intervals\n",
        "                votes.append(0)  # If interval is non-influential, append 0 votes\n",
        "                continue\n",
        "\n",
        "            vote_count = 0\n",
        "            for idx2, interval2 in enumerate(interval_list):\n",
        "                if idx2 in non_influential_sets:  # Skip non-influential intervals\n",
        "                    continue\n",
        "\n",
        "                if non_empty_intersection(interval1, interval2, inter_threshold) == 1:  # Check if intervals intersect\n",
        "                    vote_count += 1  # Increment vote count for intersecting intervals\n",
        "\n",
        "            votes.append(vote_count)  # Append the total votes for the current interval\n",
        "\n",
        "        return votes  # Return the list of votes for all intervals\n",
        "\n",
        "    ########################################################################################################################\n",
        "    ## Convex Combination Function ##\n",
        "\n",
        "    def convex_combination(pred_list, w, inter, max_weight=False):\n",
        "        \"\"\"\n",
        "        Linearly combines the two-dimensional lists only if their intersection with the reference list is non-empty.\n",
        "\n",
        "        Parameters:\n",
        "        pred_list: List of two-dimensional lists.\n",
        "        w: List of weights.\n",
        "        threshold: The threshold for the intersection/union ratio.\n",
        "\n",
        "        Returns:\n",
        "        A linearly combined list.\n",
        "        \"\"\"\n",
        "        new_interval = [0, 0]  # Initialize a new interval\n",
        "\n",
        "        if max_weight:\n",
        "            reference_list = pred_list[w.index(max(w))]  # The reference list is the one with the highest weight\n",
        "        else:\n",
        "            # Determine the reference list based on voting system\n",
        "            votes = determine_reference(pred_list, w, inter)\n",
        "            max_votes = max(votes)\n",
        "            max_vote_indices = [i for i, val in enumerate(votes) if val == max_votes]\n",
        "            selected_index = max(max_vote_indices, key=lambda i: w[i])\n",
        "            reference_list = pred_list[selected_index]\n",
        "\n",
        "        sum_weights = 0\n",
        "\n",
        "        # Iterate over each interval in pred_list\n",
        "        for i, interval in enumerate(pred_list):\n",
        "            # Calculate weight intersection\n",
        "            weight_intersection = non_empty_intersection(reference_list, interval, inter)\n",
        "\n",
        "            # Weighted interval calculation\n",
        "            weighted_interval = [w[i] * weight_intersection * end for end in interval]\n",
        "\n",
        "            # Update new_interval by adding weighted_interval\n",
        "            new_interval = [end1 + end2 for end1, end2 in zip(new_interval, weighted_interval)]\n",
        "\n",
        "            # Accumulate sum of weights\n",
        "            sum_weights += w[i] * weight_intersection\n",
        "\n",
        "        # Normalize the new_interval if sum_weights is non-zero\n",
        "        if sum_weights != 0:\n",
        "            return [end / sum_weights for end in new_interval]\n",
        "        else:\n",
        "            return -1  # Return -1 if sum_weights is zero (no valid combination found)\n",
        "\n",
        "    #########################################################################################################################\n",
        "    def iou(interval1, interval2):\n",
        "        \"\"\"\n",
        "        Calculates the Intersection over Union (IoU) of two intervals.\n",
        "        Each interval is represented as a tuple (start, end).\n",
        "\n",
        "        Parameters:\n",
        "        interval1: Tuple representing the first interval (start1, end1).\n",
        "        interval2: Tuple representing the second interval (start2, end2).\n",
        "\n",
        "        Returns:\n",
        "        IoU (Intersection over Union) value between the two intervals.\n",
        "        \"\"\"\n",
        "        start1, end1 = interval1  # Unpack interval1 into start1 and end1\n",
        "        start2, end2 = interval2  # Unpack interval2 into start2 and end2\n",
        "\n",
        "        # Calculate intersection\n",
        "        inter_start = max(start1, start2)  # Start of the intersection\n",
        "        inter_end = min(end1, end2)  # End of the intersection\n",
        "        if inter_start >= inter_end:\n",
        "            inter_len = 0  # If no intersection, length is 0\n",
        "        else:\n",
        "            inter_len = inter_end - inter_start  # Length of the intersection\n",
        "\n",
        "        # Calculate union\n",
        "        union_len = (end1 - start1) + (end2 - start2) - inter_len  # Length of the union\n",
        "\n",
        "        # Calculate IoU (Intersection over Union)\n",
        "        if union_len == 0:\n",
        "            IoU = 0  # If union length is zero, IoU is zero to avoid division by zero\n",
        "        else:\n",
        "            IoU = inter_len / union_len  # Otherwise, compute IoU\n",
        "\n",
        "        return IoU\n",
        "\n",
        "    #########################################################################################################################\n",
        "\n",
        "    def check_intervals(true_interval, predicted_intervals, n=5, threshold=0.3):\n",
        "        \"\"\"\n",
        "        Checks if at least one of the first n predicted intervals has IoU > threshold.\n",
        "\n",
        "        true_interval: Tuple (start, end) representing the true interval.\n",
        "        predicted_intervals: List of 5 tuples, each representing a predicted interval.\n",
        "        n: Number of predicted intervals to consider (from 1 to 5).\n",
        "        threshold: IoU threshold value (from 0 to 1).\n",
        "\n",
        "        Returns 1 if at least one of the first n intervals has IoU > threshold, otherwise 0.\n",
        "        \"\"\"\n",
        "        for k in range(0, n):\n",
        "            if iou(true_interval, predicted_intervals[k]) > threshold:\n",
        "                return 1\n",
        "        return 0\n",
        "\n",
        "    ########################################################################################################################\n",
        "    file_path = 'VALIDATION.csv'\n",
        "    exact_times = extract_true_intervals(file_path=file_path)\n",
        "\n",
        "    file_list = []\n",
        "    for j in range(num_mod):\n",
        "        file_list.append(f\"model_{j}.json\")\n",
        "\n",
        "    predicted_lists = {}\n",
        "    keys_list = []\n",
        "    for i, file in enumerate(file_list):\n",
        "        val_pred = json_to_csv(file)\n",
        "        key = file[:-5]  # Remove the '.json' extension from the filename to use as key\n",
        "        keys_list.append(key)\n",
        "        predicted_lists[key] = extract_5_predictions(val_pred_csv=val_pred)\n",
        "\n",
        "    ########################################################################################################################\n",
        "    ## Train set and test set division ##\n",
        "\n",
        "    length = len(exact_times)\n",
        "    split_point = round(length * split)\n",
        "\n",
        "    if split != 1:\n",
        "        test_exact_times = exact_times[split_point:]\n",
        "\n",
        "        # Loop for test set\n",
        "        test_predicted_lists = {}\n",
        "        for key in keys_list:\n",
        "            test_predicted_lists[key] = []\n",
        "            for i in range(len(predicted_lists[key])):\n",
        "                test_predicted_lists[key].append(predicted_lists[key][i][split_point:])\n",
        "\n",
        "    exact_times = exact_times[:split_point]\n",
        "\n",
        "    # Loop for train set\n",
        "    train_predicted_lists = {}\n",
        "    for key in keys_list:\n",
        "        train_predicted_lists[key] = []\n",
        "        for i in range(len(predicted_lists[key])):\n",
        "            train_predicted_lists[key].append(predicted_lists[key][i][:split_point])\n",
        "\n",
        "    ########################################################################################################################\n",
        "    ## EVALUATION of old model predictions for the WEIGHTS of CONVEX COMBINATION ##\n",
        "    ########################################################################################################################\n",
        "\n",
        "    w = []  # <- list of weights\n",
        "\n",
        "    # Dictionary definition #\n",
        "    if weight_choice == \"miou\":\n",
        "        miou_dict = {\n",
        "            'mean_vec_miou_1': None,\n",
        "            'mean_vec_miou_2': None,\n",
        "            'mean_vec_miou_3': None,\n",
        "            'mean_vec_miou': None\n",
        "        }\n",
        "\n",
        "    for j in range(num_mod):  # Model\n",
        "        # print(f\"\\n#####Related to model: {j}#####\\n\")\n",
        "        ################################################################################################################\n",
        "        ## MIoU ##\n",
        "\n",
        "        if weight_choice == \"miou\":\n",
        "            vec_miou_1 = []\n",
        "            vec_miou_3 = []\n",
        "            vec_miou_5 = []\n",
        "            vec_miou = []\n",
        "\n",
        "            ## 1 MIoU ##\n",
        "            for i in range(len(exact_times)):\n",
        "                ## MIoU computation ##\n",
        "                vec_miou_1.append(calculate_miou(exact_times[i], [train_predicted_lists[f\"model_{j}\"][0][i]]))\n",
        "            ########################################################################################################################\n",
        "            ## 3 MIoU ##\n",
        "            for i in range(len(exact_times)):\n",
        "                ## MIoU computation ##\n",
        "                vec_miou_3.append(calculate_miou(exact_times[i], [train_predicted_lists[f\"model_{j}\"][0][i],\n",
        "                                                                  train_predicted_lists[f\"model_{j}\"][1][i],\n",
        "                                                                  train_predicted_lists[f\"model_{j}\"][2][i]]))\n",
        "            ########################################################################################################################\n",
        "            ## 5 MIoU ##\n",
        "            for i in range(len(exact_times)):\n",
        "                ## MIoU computation ##\n",
        "                vec_miou_5.append(calculate_miou(exact_times[i], [train_predicted_lists[f\"model_{j}\"][0][i],\n",
        "                                                                  train_predicted_lists[f\"model_{j}\"][1][i],\n",
        "                                                                  train_predicted_lists[f\"model_{j}\"][2][i],\n",
        "                                                                  train_predicted_lists[f\"model_{j}\"][3][i],\n",
        "                                                                  train_predicted_lists[f\"model_{j}\"][4][i]]))\n",
        "            ########################################################################################################################\n",
        "            ## TOTAL MIoU ##\n",
        "            for i in range(len(exact_times)):\n",
        "                ## MIoU computation ##\n",
        "                vec_miou.append(calculate_miou(exact_times[i], [train_predicted_lists[f\"model_{j}\"][0][i]]))\n",
        "                vec_miou.append(calculate_miou(exact_times[i], [train_predicted_lists[f\"model_{j}\"][1][i]]))\n",
        "                vec_miou.append(calculate_miou(exact_times[i], [train_predicted_lists[f\"model_{j}\"][2][i]]))\n",
        "                vec_miou.append(calculate_miou(exact_times[i], [train_predicted_lists[f\"model_{j}\"][3][i]]))\n",
        "                vec_miou.append(calculate_miou(exact_times[i], [train_predicted_lists[f\"model_{j}\"][4][i]]))\n",
        "\n",
        "            average_miou = sum(vec_miou) / len(vec_miou) if vec_miou else 0\n",
        "\n",
        "            ########################################################################################################################\n",
        "            # Mean of miou #\n",
        "            miou_dict[f'mean_vec_miou_{j}'] = [np.mean(vec_miou_1), np.mean(vec_miou_3), np.mean(vec_miou_5),\n",
        "                                               average_miou]\n",
        "            ########################################################################################################################\n",
        "            # Adding the weight\n",
        "            w.append(miou_dict[f'mean_vec_miou_{j}'][miou_choice])\n",
        "\n",
        "        ################################################################################################################\n",
        "        ## Rank, inter (%) ##\n",
        "\n",
        "        elif weight_choice == \"rank_inter\":\n",
        "            summation = 0\n",
        "            for i in range(len(exact_times)):\n",
        "                predicted_intervals = [train_predicted_lists[f\"model_{j}\"][0][i],\n",
        "                                       train_predicted_lists[f\"model_{j}\"][1][i],\n",
        "                                       train_predicted_lists[f\"model_{j}\"][2][i],\n",
        "                                       train_predicted_lists[f\"model_{j}\"][3][i],\n",
        "                                       train_predicted_lists[f\"model_{j}\"][4][i]]\n",
        "                summation += check_intervals(exact_times[i], predicted_intervals=predicted_intervals, n=rank,\n",
        "                                             threshold=inter)\n",
        "\n",
        "            w.append(summation / len(exact_times) * 100)\n",
        "\n",
        "        else:\n",
        "            w.append(1)\n",
        "\n",
        "    ########################################################################################################################\n",
        "    ## ENSEMBLE ##\n",
        "    ########################################################################################################################\n",
        "\n",
        "    w = cut_below_threshold(w, threshold=influent_threshold)\n",
        "\n",
        "    w = [x ** power for x in w]\n",
        "\n",
        "    ########################################################################################################################\n",
        "    ## CONSTRUCTION OF THE ENSEMBLE FOR THE TRAIN ##\n",
        "    if split == 1:\n",
        "\n",
        "        train_pred_models = []\n",
        "        for i in range(5):\n",
        "            train_models_i = []\n",
        "            for j in range(num_mod):\n",
        "                train_models_i.append(train_predicted_lists[f\"model_{j}\"][i])\n",
        "\n",
        "            train_pred_models.append(train_models_i)\n",
        "\n",
        "        pred_0_ens = [\n",
        "            convex_combination(sublists, w, inter=inter, max_weight=max_weight) for sublists in\n",
        "            zip(*train_pred_models[0])\n",
        "        ]\n",
        "        pred_1_ens = [\n",
        "            convex_combination(sublists, w, inter=inter, max_weight=max_weight) for sublists in\n",
        "            zip(*train_pred_models[1])\n",
        "        ]\n",
        "        pred_2_ens = [\n",
        "            convex_combination(sublists, w, inter=inter, max_weight=max_weight) for sublists in\n",
        "            zip(*train_pred_models[2])\n",
        "        ]\n",
        "        pred_3_ens = [\n",
        "            convex_combination(sublists, w, inter=inter, max_weight=max_weight) for sublists in\n",
        "            zip(*train_pred_models[3])\n",
        "        ]\n",
        "        pred_4_ens = [\n",
        "            convex_combination(sublists, w, inter=inter, max_weight=max_weight) for sublists in\n",
        "            zip(*train_pred_models[4])\n",
        "        ]\n",
        "\n",
        "        ############################################################################################################################\n",
        "        ## COMBINED LIST, CONTAINS THE PREDICTION IN MATRIX FORM.\n",
        "\n",
        "        combined_list = [\n",
        "            [pred_0_ens[i], pred_1_ens[i], pred_2_ens[i], pred_3_ens[i], pred_4_ens[i]]\n",
        "            for i in range(len(pred_0_ens))\n",
        "        ]\n",
        "\n",
        "        ####################################################################################################################\n",
        "        ## EVALUATION ENSAMBLE ON TRAIN SET (just when it is needed the perfomance on the whole dataset)\n",
        "        ####################################################################################################################\n",
        "        ## MIoU ##\n",
        "\n",
        "        if weight_choice == \"miou\":\n",
        "            vec_miou_1 = []\n",
        "            vec_miou_3 = []\n",
        "            vec_miou_5 = []\n",
        "            vec_miou = []\n",
        "\n",
        "            ## 1 MIoU ##\n",
        "            for i in range(len(exact_times)):\n",
        "                ## MIoU computation ##\n",
        "                vec_miou_1.append(calculate_miou(exact_times[i], [pred_0_ens[i]]))\n",
        "            ########################################################################################################################\n",
        "            ## 3 MIoU ##\n",
        "            for i in range(len(exact_times)):\n",
        "                ## MIoU computation ##\n",
        "                vec_miou_3.append(calculate_miou(exact_times[i], [pred_0_ens[i], pred_1_ens[i], pred_2_ens[i]]))\n",
        "            ########################################################################################################################\n",
        "            ## 5 MIoU ##\n",
        "            for i in range(len(exact_times)):\n",
        "                ## MIoU computation ##\n",
        "                vec_miou_5.append(\n",
        "                    calculate_miou(exact_times[i],\n",
        "                                   [pred_0_ens[i], pred_1_ens[i], pred_2_ens[i], pred_3_ens[i], pred_4_ens[i]]))\n",
        "            ########################################################################################################################\n",
        "            ## TOTAL MIoU ##\n",
        "\n",
        "            for i in range(len(exact_times)):\n",
        "                ## MIoU computation ##\n",
        "                vec_miou.append(calculate_miou(exact_times[i], [pred_0_ens[i]]))\n",
        "                vec_miou.append(calculate_miou(exact_times[i], [pred_1_ens[i]]))\n",
        "                vec_miou.append(calculate_miou(exact_times[i], [pred_2_ens[i]]))\n",
        "                vec_miou.append(calculate_miou(exact_times[i], [pred_3_ens[i]]))\n",
        "                vec_miou.append(calculate_miou(exact_times[i], [pred_4_ens[i]]))\n",
        "\n",
        "            average_miou = sum(vec_miou) / len(vec_miou) if vec_miou else 0\n",
        "            ########################################################################################################################\n",
        "            # Mean of miou #\n",
        "            ens_vec_miou = [np.mean(vec_miou_1), np.mean(vec_miou_3), np.mean(vec_miou_5), average_miou]\n",
        "\n",
        "        ####################################################################################################################\n",
        "        ## Rank, inter (%) ##\n",
        "\n",
        "        if weight_choice == \"rank_inter\":\n",
        "            summation = 0\n",
        "            for i in range(len(exact_times)):\n",
        "                predicted_intervals = [pred_0_ens[i],\n",
        "                                       pred_1_ens[i],\n",
        "                                       pred_2_ens[i],\n",
        "                                       pred_3_ens[i],\n",
        "                                       pred_4_ens[i]]\n",
        "\n",
        "                summation += check_intervals(exact_times[i], predicted_intervals=predicted_intervals, n=rank,\n",
        "                                             threshold=inter)\n",
        "\n",
        "            rank_int_ens = summation / len(exact_times) * 100\n",
        "\n",
        "        ########################################################################################################################\n",
        "        ## EVALUATION ON THE TRAIN SET OF THE ORIGINAL MODELS TO COMPARE THEM WITH ENSEMBLE##\n",
        "        ########################################################################################################################\n",
        "\n",
        "        # Dictionary #\n",
        "        if weight_choice == \"miou\":\n",
        "            miou_dict = {\n",
        "                'mean_vec_miou_1': None,\n",
        "                'mean_vec_miou_2': None,\n",
        "                'mean_vec_miou_3': None,\n",
        "                'mean_vec': None\n",
        "            }\n",
        "\n",
        "        elif weight_choice == \"rank_inter\":\n",
        "            rank_inter_dict = {\n",
        "            }\n",
        "\n",
        "        for j in range(num_mod):  # Models\n",
        "            # print(f\"\\n#####Related to models: {j}#####\\n\")\n",
        "\n",
        "            if weight_choice == \"miou\":\n",
        "                vec_miou_1 = []\n",
        "                vec_miou_3 = []\n",
        "                vec_miou_5 = []\n",
        "                vec_miou = []\n",
        "\n",
        "                ## 1 MIoU ##\n",
        "                for i in range(len(exact_times)):\n",
        "                    ## MIoU computation ##\n",
        "                    vec_miou_1.append(\n",
        "                        calculate_miou(exact_times[i], [train_predicted_lists[f\"model_{j}\"][0][i]]))\n",
        "                ########################################################################################################################\n",
        "                ## 3 MIoU ##\n",
        "                for i in range(len(exact_times)):\n",
        "                    ## MIoU computation ##\n",
        "                    vec_miou_3.append(\n",
        "                        calculate_miou(exact_times[i], [train_predicted_lists[f\"model_{j}\"][0][i],\n",
        "                                                        train_predicted_lists[f\"model_{j}\"][1][i],\n",
        "                                                        train_predicted_lists[f\"model_{j}\"][2][\n",
        "                                                            i]]))\n",
        "                ########################################################################################################################\n",
        "                ## 5 MIoU ##\n",
        "                for i in range(len(exact_times)):\n",
        "                    ## MIoU computation ##\n",
        "                    vec_miou_5.append(\n",
        "                        calculate_miou(exact_times[i], [train_predicted_lists[f\"model_{j}\"][0][i],\n",
        "                                                        train_predicted_lists[f\"model_{j}\"][1][i],\n",
        "                                                        train_predicted_lists[f\"model_{j}\"][2][i],\n",
        "                                                        train_predicted_lists[f\"model_{j}\"][3][i],\n",
        "                                                        train_predicted_lists[f\"model_{j}\"][4][\n",
        "                                                            i]]))\n",
        "                ########################################################################################################################\n",
        "                ## TOTAL MIoU ##\n",
        "                for i in range(len(exact_times)):\n",
        "                    ## MIoU computation ##\n",
        "                    vec_miou.append(calculate_miou(exact_times[i], [train_predicted_lists[f\"model_{j}\"][0][i]]))\n",
        "                    vec_miou.append(calculate_miou(exact_times[i], [train_predicted_lists[f\"model_{j}\"][1][i]]))\n",
        "                    vec_miou.append(calculate_miou(exact_times[i], [train_predicted_lists[f\"model_{j}\"][2][i]]))\n",
        "                    vec_miou.append(calculate_miou(exact_times[i], [train_predicted_lists[f\"model_{j}\"][3][i]]))\n",
        "                    vec_miou.append(calculate_miou(exact_times[i], [train_predicted_lists[f\"model_{j}\"][4][i]]))\n",
        "\n",
        "                average_miou = sum(vec_miou) / len(vec_miou) if vec_miou else 0\n",
        "\n",
        "                ########################################################################################################################\n",
        "                # Mean of miou #\n",
        "                miou_dict[f'mean_vec_miou_{j}'] = [np.mean(vec_miou_1), np.mean(vec_miou_3), np.mean(vec_miou_5),\n",
        "                                                   average_miou]\n",
        "\n",
        "            elif weight_choice == \"rank_inter\":\n",
        "                summation = 0\n",
        "                for i in range(len(exact_times)):\n",
        "                    summation += check_intervals(exact_times[i], [train_predicted_lists[f\"model_{j}\"][0][i],\n",
        "                                                                  train_predicted_lists[f\"model_{j}\"][1][i],\n",
        "                                                                  train_predicted_lists[f\"model_{j}\"][2][i],\n",
        "                                                                  train_predicted_lists[f\"model_{j}\"][3][i],\n",
        "                                                                  train_predicted_lists[f\"model_{j}\"][4][i]],\n",
        "                                                 n=rank,\n",
        "                                                 threshold=inter)\n",
        "                rank_inter_dict[f'rank_inter_{j}'] = summation / len(exact_times) * 100\n",
        "\n",
        "        if comparison == \"best\":\n",
        "            best_list = []  # Fictitious\n",
        "            ########################################################################################################################\n",
        "            ## PRINT OF THE RESULTS OBTAINED FROM THE SUPPOSED BEST AND COMPARE THEM WITH THE ENSEMBLE ##\n",
        "\n",
        "            # Step 1: Find the index of the largest value in the list\n",
        "            max_index = w.index(max(w))\n",
        "\n",
        "            ## MMIoU ##\n",
        "            if weight_choice == \"miou\":\n",
        "                # Step 2: Get the corresponding key from the dictionary\n",
        "                max_key = list(miou_dict.keys())[max_index]\n",
        "\n",
        "                # Step 3: Retrieve the value from the dictionary using the key\n",
        "                best_miou = miou_dict[max_key]\n",
        "\n",
        "                print(\n",
        "                    f\"The results of the supposed best (w.r.t. {weight_choice}) for the MMIoU  1, 3, 5 and total respectively are: {best_miou[0]}, {best_miou[1]}, {best_miou[2]}, {best_miou[3]}\")\n",
        "                print(\n",
        "                    f\"The results given by the Ensemble are:{ens_vec_miou[0]}, {ens_vec_miou[1]}, {ens_vec_miou[2]}, {ens_vec_miou[3]}\")\n",
        "\n",
        "                return best_miou, ens_vec_miou, combined_list, best_list\n",
        "\n",
        "            ## Rank, inter (%) ##\n",
        "            if weight_choice == \"rank_inter\":\n",
        "                # Step 2: Get the corresponding key from the dictionary\n",
        "                max_key = list(rank_inter_dict.keys())[max_index]\n",
        "\n",
        "                # Step 3: Retrieve the value from the dictionary using the key\n",
        "                best_rank_inter = rank_inter_dict[max_key]\n",
        "\n",
        "                print(\n",
        "                    f\"The best (w.r.t. {weight_choice}) single-model result obtained with rank: {rank}, IoU: {inter} (%) was: {best_rank_inter}. \\nThe Ensemble gave back: {rank_int_ens}.\")\n",
        "\n",
        "                return best_rank_inter, rank_int_ens, combined_list, best_list\n",
        "\n",
        "        elif comparison == \"all\":\n",
        "            best_list = []  # Fictitious\n",
        "            ########################################################################################################################\n",
        "            ## PRINT OF THE BEST RESULTS OBTAINED AND COMPARE THEM WITH THE ENSEMBLE ##\n",
        "\n",
        "            ## MMIoU ##\n",
        "            if weight_choice == \"miou\":\n",
        "\n",
        "                max_first = float('-inf')\n",
        "                max_second = float('-inf')\n",
        "                max_third = float('-inf')\n",
        "                max_fourth = float('-inf')\n",
        "\n",
        "                for values in miou_dict.values():\n",
        "                    if values is not None:\n",
        "                        if values[0] > max_first:\n",
        "                            max_first = values[0]\n",
        "                        if values[1] > max_second:\n",
        "                            max_second = values[1]\n",
        "                        if values[2] > max_third:\n",
        "                            max_third = values[2]\n",
        "                        if values[3] > max_fourth:\n",
        "                            max_fourth = values[3]\n",
        "\n",
        "                maximum = [max_first, max_second, max_third, max_fourth]\n",
        "                print(\n",
        "                    f\"The aggregate best results for the MMIoU  1, 3 and 5 respectively are: {maximum[0]}, {maximum[1]}, {maximum[2]}, {maximum[3]}\")\n",
        "                print(\n",
        "                    f\"The results given by the Ensemble are:{ens_vec_miou[0]}, {ens_vec_miou[1]}, {ens_vec_miou[2]}, {ens_vec_miou[3]}\")\n",
        "\n",
        "                return maximum, ens_vec_miou, combined_list, best_list\n",
        "\n",
        "            ## Rank, inter (%) ##\n",
        "            if weight_choice == \"rank_inter\":\n",
        "                max_value = 0\n",
        "                for value in rank_inter_dict.values():\n",
        "                    if not isinstance(value, list):\n",
        "                        if value > max_value:\n",
        "                            max_value = value\n",
        "                print(\n",
        "                    f\"The aggregate best single-model result obtained with rank: {rank}, IoU: {inter} (%) was: {max_value}. \\nThe Ensemble gave back: {rank_int_ens}.\")\n",
        "\n",
        "                return max_value, rank_int_ens, combined_list, best_list\n",
        "    ########################################################################################################################\n",
        "    ## CONSTRUCTION OF THE ENSEMBLE FOR THE TEST ##\n",
        "    elif split != 1:\n",
        "\n",
        "        test_pred_models = []\n",
        "        for i in range(5):\n",
        "            test_models_i = []\n",
        "            for j in range(num_mod):\n",
        "                test_models_i.append(test_predicted_lists[f\"model_{j}\"][i])\n",
        "\n",
        "            test_pred_models.append(test_models_i)\n",
        "\n",
        "        pred_0_ens = [\n",
        "            convex_combination(sublists, w, inter=inter, max_weight=max_weight) for sublists in\n",
        "            zip(*test_pred_models[0])\n",
        "        ]\n",
        "        pred_1_ens = [\n",
        "            convex_combination(sublists, w, inter=inter, max_weight=max_weight) for sublists in\n",
        "            zip(*test_pred_models[1])\n",
        "        ]\n",
        "        pred_2_ens = [\n",
        "            convex_combination(sublists, w, inter=inter, max_weight=max_weight) for sublists in\n",
        "            zip(*test_pred_models[2])\n",
        "        ]\n",
        "        pred_3_ens = [\n",
        "            convex_combination(sublists, w, inter=inter, max_weight=max_weight) for sublists in\n",
        "            zip(*test_pred_models[3])\n",
        "        ]\n",
        "        pred_4_ens = [\n",
        "            convex_combination(sublists, w, inter=inter, max_weight=max_weight) for sublists in\n",
        "            zip(*test_pred_models[4])\n",
        "        ]\n",
        "\n",
        "        ############################################################################################################################\n",
        "        ## COMBINED LIST, CONTAINS THE PREDICTION OF ENSEMBLE IN MATRIX FORM.\n",
        "\n",
        "        combined_list = [\n",
        "            [pred_0_ens[i], pred_1_ens[i], pred_2_ens[i], pred_3_ens[i], pred_4_ens[i]]\n",
        "            for i in range(len(pred_0_ens))\n",
        "        ]\n",
        "\n",
        "        ########################################################################################################################\n",
        "        ## EVALUATION ENSEMBLE ON TEST ##\n",
        "        ########################################################################################################################\n",
        "        ## MIOU ##\n",
        "\n",
        "        if weight_choice == \"miou\":\n",
        "            vec_miou_1 = []\n",
        "            vec_miou_3 = []\n",
        "            vec_miou_5 = []\n",
        "            vec_miou = []\n",
        "\n",
        "            ## 1 MIoU ##\n",
        "            for i in range(len(test_exact_times)):\n",
        "                ## MIoU computation ##\n",
        "                vec_miou_1.append(calculate_miou(test_exact_times[i], [pred_0_ens[i]]))\n",
        "            ########################################################################################################################\n",
        "            ## 3 MIoU ##\n",
        "            for i in range(len(test_exact_times)):\n",
        "                ## MIoU computation ##\n",
        "                vec_miou_3.append(calculate_miou(test_exact_times[i], [pred_0_ens[i], pred_1_ens[i], pred_2_ens[i]]))\n",
        "            ########################################################################################################################\n",
        "            ## 5 MIoU ##\n",
        "            for i in range(len(test_exact_times)):\n",
        "                ## MIoU computation ##\n",
        "                vec_miou_5.append(calculate_miou(test_exact_times[i],\n",
        "                                                 [pred_0_ens[i], pred_1_ens[i], pred_2_ens[i], pred_3_ens[i],\n",
        "                                                  pred_4_ens[i]]))\n",
        "            ########################################################################################################################\n",
        "            ## TOTAL MIoU ##\n",
        "\n",
        "            for i in range(len(test_exact_times)):\n",
        "                ## MIoU computation ##\n",
        "                vec_miou.append(calculate_miou(test_exact_times[i], [pred_0_ens[i]]))\n",
        "                vec_miou.append(calculate_miou(test_exact_times[i], [pred_1_ens[i]]))\n",
        "                vec_miou.append(calculate_miou(test_exact_times[i], [pred_2_ens[i]]))\n",
        "                vec_miou.append(calculate_miou(test_exact_times[i], [pred_3_ens[i]]))\n",
        "                vec_miou.append(calculate_miou(test_exact_times[i], [pred_4_ens[i]]))\n",
        "\n",
        "            average_miou = sum(vec_miou) / len(vec_miou) if vec_miou else 0\n",
        "\n",
        "            ########################################################################################################################\n",
        "            # Mean of miou #\n",
        "            ens_vec_miou = [np.mean(vec_miou_1), np.mean(vec_miou_3), np.mean(vec_miou_5), average_miou]\n",
        "\n",
        "        ####################################################################################################################\n",
        "        ## Rank, inter (%) ##\n",
        "\n",
        "        if weight_choice == \"rank_inter\":\n",
        "            summation = 0\n",
        "\n",
        "            for i in range(len(test_exact_times)):\n",
        "                predicted_intervals = [pred_0_ens[i],\n",
        "                                       pred_1_ens[i],\n",
        "                                       pred_2_ens[i],\n",
        "                                       pred_3_ens[i],\n",
        "                                       pred_4_ens[i]]\n",
        "\n",
        "                summation += check_intervals(test_exact_times[i], predicted_intervals=predicted_intervals, n=rank,\n",
        "                                             threshold=inter)\n",
        "\n",
        "            rank_int_ens = summation / len(test_exact_times) * 100\n",
        "\n",
        "        ############################################################################################################################\n",
        "        ## BEST LIST, CONTAINS THE PREDICTION OF THE SUPPOSED BEST MODEL IN MATRIX FORM.\n",
        "        max_index = w.index(max(w))\n",
        "\n",
        "        best_list = [\n",
        "            [test_predicted_lists[f\"model_{max_index}\"][0][i], test_predicted_lists[f\"model_{max_index}\"][1][i], test_predicted_lists[f\"model_{max_index}\"][2][i], test_predicted_lists[f\"model_{max_index}\"][3][i], test_predicted_lists[f\"model_{max_index}\"][4][i]]\n",
        "            for i in range(len(test_predicted_lists[f\"model_{max_index}\"][0]))\n",
        "        ]\n",
        "\n",
        "        ########################################################################################################################\n",
        "        ## EVALUATION ON THE TEST SET OF THE ORIGINAL MODEL TO COMPARE THEM WITH ENSEMBLE##\n",
        "        ########################################################################################################################\n",
        "\n",
        "        # Dictionary #\n",
        "        if weight_choice == \"miou\":\n",
        "            miou_dict = {\n",
        "                'mean_vec_miou_1': None,\n",
        "                'mean_vec_miou_2': None,\n",
        "                'mean_vec_miou_3': None,\n",
        "                'mean_vec_miou': None\n",
        "            }\n",
        "\n",
        "        elif weight_choice == \"rank_inter\":\n",
        "            rank_inter_dict = {\n",
        "            }\n",
        "\n",
        "        for j in range(num_mod):  # Models\n",
        "            # print(f\"\\n#####Related to models: {j}#####\\n\")\n",
        "            if weight_choice == \"miou\":\n",
        "                vec_miou_1 = []\n",
        "                vec_miou_3 = []\n",
        "                vec_miou_5 = []\n",
        "                vec_miou = []\n",
        "\n",
        "                ## 1 MIoU ##\n",
        "                for i in range(len(test_exact_times)):\n",
        "                    ## MIoU computation ##\n",
        "                    vec_miou_1.append(\n",
        "                        calculate_miou(test_exact_times[i], [test_predicted_lists[f\"model_{j}\"][0][i]]))\n",
        "                ########################################################################################################################\n",
        "                ## 3 MIoU ##\n",
        "                for i in range(len(test_exact_times)):\n",
        "                    ## MIoU computation ##\n",
        "                    vec_miou_3.append(calculate_miou(test_exact_times[i], [test_predicted_lists[f\"model_{j}\"][0][i],\n",
        "                                                                           test_predicted_lists[f\"model_{j}\"][1][i],\n",
        "                                                                           test_predicted_lists[f\"model_{j}\"][2][\n",
        "                                                                               i]]))\n",
        "                ########################################################################################################################\n",
        "                ## 5 MIoU ##\n",
        "                for i in range(len(test_exact_times)):\n",
        "                    ## MIoU computation ##\n",
        "                    vec_miou_5.append(calculate_miou(test_exact_times[i], [test_predicted_lists[f\"model_{j}\"][0][i],\n",
        "                                                                           test_predicted_lists[f\"model_{j}\"][1][i],\n",
        "                                                                           test_predicted_lists[f\"model_{j}\"][2][i],\n",
        "                                                                           test_predicted_lists[f\"model_{j}\"][3][i],\n",
        "                                                                           test_predicted_lists[f\"model_{j}\"][4][\n",
        "                                                                               i]]))\n",
        "                ########################################################################################################################\n",
        "                ## TOTAL MIoU ##\n",
        "                for i in range(len(test_exact_times)):\n",
        "                    ## MIoU computation ##\n",
        "                    vec_miou.append(calculate_miou(test_exact_times[i], [test_predicted_lists[f\"model_{j}\"][0][i]]))\n",
        "                    vec_miou.append(calculate_miou(test_exact_times[i], [test_predicted_lists[f\"model_{j}\"][1][i]]))\n",
        "                    vec_miou.append(calculate_miou(test_exact_times[i], [test_predicted_lists[f\"model_{j}\"][2][i]]))\n",
        "                    vec_miou.append(calculate_miou(test_exact_times[i], [test_predicted_lists[f\"model_{j}\"][3][i]]))\n",
        "                    vec_miou.append(calculate_miou(test_exact_times[i], [test_predicted_lists[f\"model_{j}\"][4][i]]))\n",
        "\n",
        "                average_miou = sum(vec_miou) / len(vec_miou) if vec_miou else 0\n",
        "\n",
        "                ########################################################################################################################\n",
        "                # Mean of miou #\n",
        "                miou_dict[f'mean_vec_miou_{j}'] = [np.mean(vec_miou_1), np.mean(vec_miou_3), np.mean(vec_miou_5),\n",
        "                                                   average_miou]\n",
        "\n",
        "            elif weight_choice == \"rank_inter\":\n",
        "                summation = 0\n",
        "                for i in range(len(test_exact_times)):\n",
        "                    summation += check_intervals(test_exact_times[i], [test_predicted_lists[f\"model_{j}\"][0][i],\n",
        "                                                                       test_predicted_lists[f\"model_{j}\"][1][i],\n",
        "                                                                       test_predicted_lists[f\"model_{j}\"][2][i],\n",
        "                                                                       test_predicted_lists[f\"model_{j}\"][3][i],\n",
        "                                                                       test_predicted_lists[f\"model_{j}\"][4][i]],\n",
        "                                                 n=rank,\n",
        "                                                 threshold=inter)\n",
        "                rank_inter_dict[f'rank_inter_{j}'] = summation / len(test_exact_times) * 100\n",
        "\n",
        "                # print(f\"rank: {rank}, IoU: {inter} (%)\", rank_inter_dict[f'rank_inter_{j}_{r}'])\n",
        "\n",
        "        if comparison == \"best\":\n",
        "            ########################################################################################################################\n",
        "            ## PRINT OF THE RESULTS OBTAINED FROM THE SUPPOSED BEST AND COMPARE THEM WITH THE ENSEMBLE ##\n",
        "\n",
        "            # Step 1: Find the index of the largest value in the list\n",
        "            max_index = w.index(max(w))\n",
        "\n",
        "            ## MMIoU ##\n",
        "            if weight_choice == \"miou\":\n",
        "                # Step 2: Get the corresponding key from the dictionary\n",
        "                max_key = list(miou_dict.keys())[max_index]\n",
        "\n",
        "                # Step 3: Retrieve the value from the dictionary using the key\n",
        "                best_miou = miou_dict[max_key]\n",
        "\n",
        "                print(\n",
        "                    f\"The results of the supposed best (w.r.t. {weight_choice}) for the MMIoU  1, 3, 5 and total respectively are: {best_miou[0]}, {best_miou[1]}, {best_miou[2]}, {best_miou[3]}\")\n",
        "                print(\n",
        "                    f\"The results given by the Ensemble are:{ens_vec_miou[0]}, {ens_vec_miou[1]}, {ens_vec_miou[2]}, {ens_vec_miou[3]}\")\n",
        "\n",
        "                return best_miou, ens_vec_miou, combined_list, best_list\n",
        "\n",
        "            ## Rank, inter (%) ##\n",
        "            if weight_choice == \"rank_inter\":\n",
        "                # Step 2: Get the corresponding key from the dictionary\n",
        "                max_key = list(rank_inter_dict.keys())[max_index]\n",
        "\n",
        "                # Step 3: Retrieve the value from the dictionary using the key\n",
        "                best_rank_inter = rank_inter_dict[max_key]\n",
        "\n",
        "                print(\n",
        "                    f\"The best (w.r.t. {weight_choice}) single-model result obtained with rank: {rank}, IoU: {inter} (%) was: {best_rank_inter}. \\nThe Ensemble gave back: {rank_int_ens}.\")\n",
        "\n",
        "                return best_rank_inter, rank_int_ens, combined_list, best_list\n",
        "\n",
        "        elif comparison == \"all\":\n",
        "            best_list = []  # Fictitious\n",
        "            ########################################################################################################################\n",
        "            ## PRINT OF THE BEST RESULTS OBTAINED AND COMPARE THEM WITH THE ENSEMBLE ##\n",
        "\n",
        "            ## MMIoU ##\n",
        "            if weight_choice == \"miou\":\n",
        "\n",
        "                max_first = float('-inf')\n",
        "                max_second = float('-inf')\n",
        "                max_third = float('-inf')\n",
        "                max_fourth = float('-inf')\n",
        "\n",
        "                for values in miou_dict.values():\n",
        "                    if values is not None:\n",
        "                        if values[0] > max_first:\n",
        "                            max_first = values[0]\n",
        "                        if values[1] > max_second:\n",
        "                            max_second = values[1]\n",
        "                        if values[2] > max_third:\n",
        "                            max_third = values[2]\n",
        "                        if values[3] > max_fourth:\n",
        "                            max_fourth = values[3]\n",
        "\n",
        "                maximum = [max_first, max_second, max_third, max_fourth]\n",
        "                print(\n",
        "                    f\"The aggregate best results for the MMIoU  1, 3 and 5 respectively are: {maximum[0]}, {maximum[1]}, {maximum[2]}, {maximum[3]}\")\n",
        "                print(\n",
        "                    f\"The results given by the Ensemble are:{ens_vec_miou[0]}, {ens_vec_miou[1]}, {ens_vec_miou[2]}, {ens_vec_miou[3]}\")\n",
        "\n",
        "                return maximum, ens_vec_miou, combined_list, best_list\n",
        "\n",
        "            ## Rank, inter (%) ##\n",
        "            if weight_choice == \"rank_inter\":\n",
        "                max_value = 0\n",
        "                for value in rank_inter_dict.values():\n",
        "                    if not isinstance(value, list):\n",
        "                        if value > max_value:\n",
        "                            max_value = value\n",
        "                print(\n",
        "                    f\"The aggregate best single-model result obtained with rank: {rank}, IoU: {inter} (%) was: {max_value}. \\nThe Ensemble gave back: {rank_int_ens}.\")\n",
        "\n",
        "                return max_value, rank_int_ens, combined_list, best_list\n",
        "\n",
        "\n",
        "########################################################################################################################\n",
        "## FIXED-PARAMETERS ##\n",
        "\n",
        "num_mod = 153\n",
        "\n",
        "split = 0.67\n",
        "\n",
        "miou_choice = 0\n",
        "########################################################################################################################\n",
        "## GRID-SEARCH ##\n",
        "\n",
        "## Important observation: Note that rank 5 as a measure of choosing the best model is significantly worse than rank 1. This can be intuitively explained by the fact that if you hypothetically have a model with all 5 predicted intervals being different, it indicates that the model was potentially not very confident in the first interval, which is the one we are most interested in. Therefore, a behavior would be positively evaluated that in reality is not. ##\n",
        "\n",
        "hyper_p = []\n",
        "grids = []\n",
        "combined = []\n",
        "best = []\n",
        "linear_variations = []\n",
        "for comparison in [\"best\"]:  # in [\"best\", \"all\"]\n",
        "    for max_weight in [True, False]:  # True is largerly worse than the False. FINAL CHOICE: [True, False]\n",
        "        for rank in [1]:  # (metric rank_inter) -> 2 worse than 5 which is worse than 1 itself. FINAL CHOICE: [1] Look up for the reason.\n",
        "            for inter in [0.5, 0.3]:  # (metric miou) -> 0.1 worse than 0.3, 0.5  # (metric rank_inter) -> 0.3 gives back slightly higher peaks, but in general they show similar behaviours. FINAL CHOICE: [0.5, 0.3]\n",
        "                for metric in [\"miou\", \"rank_inter\"]:  # (metric rank_inter) -> eventhough metric rank_inter is widely used, the more stable results are given by the miou. FINAL CHOICE: [\"miou\", \"rank_inter\"]\n",
        "                    for influent_threshold in [0.8, 0.67]:  # (metric rank_inter) -> 0.8 worse than 0.67. FINAL CHOICE: [0.8, 0.67]\n",
        "                        for power in [1, 10, 100]:  # Heuristically, 1, 10, 100.\n",
        "                            print(f\"###The hyper-parameters set: split: {split}, rank: {rank}, inter: {inter}, metric: {metric}, miou_choice: {miou_choice}, influent_threshold: {influent_threshold}, power: {power}, max_weight: {max_weight}, comparison: {comparison}### \")\n",
        "\n",
        "                            hyper_p.append([split, rank, inter, metric, miou_choice, influent_threshold, power, max_weight,comparison])\n",
        "\n",
        "                            grid = ensemble(num_mod, split, rank, inter, miou_choice, metric, influent_threshold, power, max_weight, comparison)\n",
        "\n",
        "                            grids.append(grid)\n",
        "                            if metric == \"miou\":\n",
        "                                lin_var = (grid[1][miou_choice] - grid[0][miou_choice]) / grid[0][miou_choice] * 100\n",
        "                                linear_variations.append(lin_var)\n",
        "                                combined.append(\n",
        "                                    [split, rank, inter, metric, miou_choice, influent_threshold, power, max_weight,\n",
        "                                     comparison, lin_var, grid[2]])\n",
        "                                best.append(\n",
        "                                    [split, rank, inter, metric, miou_choice, influent_threshold, power, max_weight,\n",
        "                                     comparison, lin_var, grid[3]])\n",
        "\n",
        "                            elif metric == \"rank_inter\":\n",
        "                                lin_var = (grid[1] - grid[0]) / grid[0] * 100\n",
        "                                linear_variations.append(lin_var)\n",
        "                                combined.append(\n",
        "                                    [split, rank, inter, metric, miou_choice, influent_threshold, power, max_weight,\n",
        "                                     comparison, lin_var, grid[2]])\n",
        "                                best.append(\n",
        "                                    [split, rank, inter, metric, miou_choice, influent_threshold, power, max_weight,\n",
        "                                     comparison, lin_var, grid[3]])\n",
        "                            print(\"\\n\")\n",
        "\n",
        "########################################################################################################################\n",
        "## SAVING HYPER-PARAMETERS AND PREDICTIONS INTO A CSV FILE\n",
        "\n",
        "# Creating a DataFrame from the combined list\n",
        "df_combined = pd.DataFrame(combined)\n",
        "df_best = pd.DataFrame(best)\n",
        "\n",
        "# Adding columns conditionally\n",
        "if metric == \"miou\":\n",
        "    df_combined.columns = [\"split\", \"rank\", \"inter\", \"metric\", \"miou_choice\", \"influent_threshold\", \"power\",\n",
        "                           \"max_weight\", \"comparison\", \"miou\", \"pred\"]\n",
        "    df_best.columns = [\"split\", \"rank\", \"inter\", \"metric\", \"miou_choice\", \"influent_threshold\", \"power\",\n",
        "                           \"max_weight\", \"comparison\", \"miou\", \"pred\"]\n",
        "elif metric == \"rank_inter\":\n",
        "    df_combined.columns = [\"split\", \"rank\", \"inter\", \"metric\", \"miou_choice\", \"influent_threshold\", \"power\",\n",
        "                           \"max_weight\", \"comparison\", \"rank_inter\", \"pred\"]\n",
        "    df_best.columns = [\"split\", \"rank\", \"inter\", \"metric\", \"miou_choice\", \"influent_threshold\", \"power\",\n",
        "                           \"max_weight\", \"comparison\", \"rank_inter\", \"pred\"]\n",
        "\n",
        "df_combined.to_csv('df_combined.csv', index=False)\n",
        "df_best.to_csv('df_best.csv', index=False)\n",
        "\n",
        "########################################################################################################################\n",
        "## WRITING ON \"OUTPUT.TXT\" FILE THE BEST AND THE WORST CONFIGURATIONS ##\n",
        "\n",
        "file = \"output.txt\"\n",
        "with open(file, 'w') as file:\n",
        "    positive_values = [(index, value) for index, value in enumerate(linear_variations) if value > 0]\n",
        "    top_positive = sorted(positive_values, key=lambda x: x[1], reverse=True)[:int(len(linear_variations) / 4)]\n",
        "\n",
        "    negative_values = [(index, value) for index, value in enumerate(linear_variations) if value < 0]\n",
        "    top_negative = sorted(negative_values, key=lambda x: x[1])[:int(len(linear_variations) / 4)]\n",
        "\n",
        "    for index, value in top_positive:\n",
        "        print(\n",
        "            f\"The hyper-parameters set: split: {hyper_p[index][0]}, rank: {hyper_p[index][1]}, inter: {hyper_p[index][2]}, metric: {hyper_p[index][3]}, miou_choice: {hyper_p[index][4]}, influent_threshold: {hyper_p[index][5]}, power: {hyper_p[index][6]}, max_weight: {hyper_p[index][7]}, comparison: {hyper_p[index][8]}###\",\n",
        "            file=file)\n",
        "        print(\n",
        "            f\"results: {grids[index][0]}, {grids[index][1]}, \\nlinear variations: {np.round(linear_variations[index], 4)} (%)\",\n",
        "            file=file)\n",
        "\n",
        "    for index, value in top_negative:\n",
        "        print(\n",
        "            f\"The hyper-parameters set: split: {hyper_p[index][0]}, rank: {hyper_p[index][1]}, inter: {hyper_p[index][2]}, metric: {hyper_p[index][3]}, miou_choice: {hyper_p[index][4]}, influent_threshold: {hyper_p[index][5]}, power: {hyper_p[index][6]}, max_weight: {hyper_p[index][7]}, comparison: {hyper_p[index][8]}###\",\n",
        "            file=file)\n",
        "        print(\n",
        "            f\"results: {grids[index][0]}, {grids[index][1]}, \\nlinear variations: {np.round(linear_variations[index], 4)} (%)\",\n",
        "            file=file)\n",
        "\n",
        "########################################################################################################################\n",
        "## COLOR PRINTING TO VISUALIZE THE RESULTS ##\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "values = linear_variations\n",
        "# Separate positive and negative values\n",
        "positive_values = np.maximum(0, linear_variations)\n",
        "negative_values = np.minimum(0, linear_variations)\n",
        "\n",
        "# Normalize positive values between 0 and 1\n",
        "norm_positive_values = positive_values / positive_values.max() if positive_values.max() != 0 else positive_values\n",
        "\n",
        "# Normalize negative values between 0 and 1\n",
        "norm_negative_values = negative_values / negative_values.min() if negative_values.min() != 0 else negative_values\n",
        "\n",
        "# Create colormaps for positive and negative values\n",
        "colormap_positive = plt.get_cmap('Reds')\n",
        "colormap_negative = plt.get_cmap('Blues_r')  # '_r' to get the reversed colormap\n",
        "\n",
        "# Assign colors\n",
        "colors = []\n",
        "for value in linear_variations:\n",
        "    if value > 0:\n",
        "        color = colormap_positive(value / positive_values.max())\n",
        "    elif value < 0:\n",
        "        color = colormap_negative(value / negative_values.min())\n",
        "    else:\n",
        "        color = (1, 1, 1, 1)  # White color for zero\n",
        "    colors.append(color)\n",
        "\n",
        "# Create a figure and axis\n",
        "fig, ax = plt.subplots(figsize=(15, 2))\n",
        "\n",
        "# Remove axes and borders\n",
        "ax.axis('off')\n",
        "\n",
        "# Create the one-dimensional heatmap\n",
        "for j in range(len(linear_variations)):\n",
        "    ax.add_patch(plt.Rectangle((j, 0), 1, 1, color=colors[j]))\n",
        "\n",
        "# Show the heatmap\n",
        "plt.xlim(0, len(linear_variations))\n",
        "plt.ylim(0, 1)\n",
        "\n",
        "# Add a colorbar as a legend\n",
        "sm_positive = plt.cm.ScalarMappable(cmap=colormap_positive, norm=plt.Normalize(vmin=0, vmax=positive_values.max()))\n",
        "sm_negative = plt.cm.ScalarMappable(cmap=colormap_negative, norm=plt.Normalize(vmin=negative_values.min(), vmax=0))\n",
        "\n",
        "# Configure and display the colorbar for positive values\n",
        "cbar_positive = plt.colorbar(sm_positive, ax=ax, orientation='horizontal', pad=0.1, aspect=40, shrink=0.8)\n",
        "cbar_positive.set_label('Positive Values')\n",
        "\n",
        "# Configure and display the colorbar for negative values\n",
        "cbar_negative = plt.colorbar(sm_negative, ax=ax, orientation='horizontal', pad=0.3, aspect=40, shrink=0.8)\n",
        "cbar_negative.set_label('Negative Values')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "########################################################################################################################\n",
        "## READING THE PREDICTION OF THE BEST ENSEMBLE MODEL TAKEN FROM THE \"OUTPUT.TXT\" FILE ##\n",
        "\n",
        "file = \"output.txt\"\n",
        "# Open the file in read mode\n",
        "with open(file, 'r') as file:\n",
        "    # Read the first line\n",
        "    parameters_line = file.readline()\n",
        "\n",
        "    # The correct regex pattern\n",
        "    pattern = r\"split: (\\d+\\.\\d+), rank: (\\d+), inter: (\\d+\\.\\d+), metric: (\\w+), miou_choice: (\\d+), influent_threshold: (\\d+\\.\\d+), power: (\\d+), max_weight: (True|False), comparison: (\\w+)\"\n",
        "\n",
        "    # Search for the pattern in the string\n",
        "    match = re.search(pattern, parameters_line)\n",
        "\n",
        "    if match:\n",
        "        split = float(match.group(1))\n",
        "        rank = int(match.group(2))\n",
        "        inter = float(match.group(3))\n",
        "        metric = match.group(4)\n",
        "        miou_choice = int(match.group(5))\n",
        "        influent_threshold = float(match.group(6))\n",
        "        power = int(match.group(7))\n",
        "        max_weight = match.group(8) == \"True\"\n",
        "        comparison = match.group(9)\n",
        "\n",
        "        # Creating a dictionary with the parameters\n",
        "        params = {\n",
        "            \"metric\": metric,\n",
        "            'split': split,\n",
        "            'rank': rank,\n",
        "            'inter': inter,\n",
        "            'miou_choice': miou_choice,\n",
        "            'influent_threshold': influent_threshold,\n",
        "            'power': power,\n",
        "            'max_weight': max_weight,\n",
        "            'comparison': comparison\n",
        "        }\n",
        "\n",
        "        # Print the parameter dictionary\n",
        "        print(params)\n",
        "\n",
        "        # Filter the df_combined DataFrame using the parameter values\n",
        "\n",
        "        # Filtering the DataFrame using the parameter values\n",
        "        filtro = (\n",
        "                (df_combined['split'] == params['split']) &\n",
        "                (df_combined['rank'] == params['rank']) &\n",
        "                (df_combined['inter'] == params['inter']) &\n",
        "                (df_combined['miou_choice'] == params['miou_choice']) &\n",
        "                (df_combined['influent_threshold'] == params['influent_threshold']) &\n",
        "                (df_combined['power'] == params['power']) &\n",
        "                (df_combined['max_weight'] == params['max_weight']) &\n",
        "                (df_combined['comparison'] == params['comparison']) &\n",
        "                (df_combined['metric'] == params['metric'])\n",
        "        )\n",
        "\n",
        "        ## Here the prediction delivered from the supposed best, for the run that built the ensemble, is selected.\n",
        "\n",
        "        filtro_best = (\n",
        "                (df_best['split'] == params['split']) &\n",
        "                (df_best['rank'] == params['rank']) &\n",
        "                (df_best['inter'] == params['inter']) &\n",
        "                (df_best['miou_choice'] == params['miou_choice']) &\n",
        "                (df_best['influent_threshold'] == params['influent_threshold']) &\n",
        "                (df_best['power'] == params['power']) &\n",
        "                (df_best['max_weight'] == params['max_weight']) &\n",
        "                (df_best['comparison'] == params['comparison']) &\n",
        "                (df_best['metric'] == params['metric'])\n",
        "        )\n",
        "\n",
        "        # Apply the filter\n",
        "        df_filtered = df_combined[filtro]\n",
        "        df_best_filtered = df_best[filtro_best]\n",
        "\n",
        "        ################################################################################################################\n",
        "        ## ENSEMBLE ##\n",
        "        ################################################################################################################\n",
        "        # Access the 'pred' column of the filtered row\n",
        "        if not df_filtered.empty:\n",
        "            pred_value = df_filtered.iloc[0]['pred']\n",
        "            # print(pred_value)\n",
        "        else:\n",
        "            print(\"No matching rows found\")\n",
        "\n",
        "        # Create a list of dictionaries to build the DataFrame\n",
        "        rows = []\n",
        "        for sublist in pred_value:\n",
        "            row_dict = {\n",
        "                'col1': sublist[0],\n",
        "                'col2': sublist[1],\n",
        "                'col3': sublist[2],\n",
        "                'col4': sublist[3],\n",
        "                'col5': sublist[4]\n",
        "            }\n",
        "            rows.append(row_dict)\n",
        "\n",
        "        # Create the DataFrame\n",
        "        df_pred_value = pd.DataFrame(rows)\n",
        "\n",
        "        # Write the DataFrame to CSV file\n",
        "        csv_file_path = \"predictions.csv\"\n",
        "        df_pred_value.to_csv(csv_file_path, index=False)\n",
        "\n",
        "        print(f\"Predictions written to {csv_file_path}\")\n",
        "\n",
        "        ################################################################################################################\n",
        "        ## BEST ##\n",
        "        ################################################################################################################\n",
        "        # Access the 'pred' column of the filtered row\n",
        "        if not df_best_filtered.empty:\n",
        "            best_pred_value = df_best_filtered.iloc[0]['pred']\n",
        "            # print(best_pred_value)\n",
        "        else:\n",
        "            print(\"No matching rows found\")\n",
        "\n",
        "        # Create a list of dictionaries to build the DataFrame\n",
        "        rows = []\n",
        "        for sublist in best_pred_value:\n",
        "            row_dict = {\n",
        "                'col1': sublist[0],\n",
        "                'col2': sublist[1],\n",
        "                'col3': sublist[2],\n",
        "                'col4': sublist[3],\n",
        "                'col5': sublist[4]\n",
        "            }\n",
        "            rows.append(row_dict)\n",
        "\n",
        "        # Create the DataFrame\n",
        "        df_best_pred_value = pd.DataFrame(rows)\n",
        "\n",
        "        # Write the DataFrame to CSV file\n",
        "        csv_file_path = \"predictions_best.csv\"\n",
        "        df_best_pred_value.to_csv(csv_file_path, index=False)\n",
        "\n",
        "        print(f\"Predictions written to {csv_file_path}\")\n",
        "\n",
        "    else:\n",
        "        print(\"No match found for parameters in the string.\")\n",
        "\n",
        "########################################################################################################################\n",
        "## REWRITING ENTRIES OF THE SOURCE FILE TO INCLUDE ENSEMBLE PREDICTIONS FOR EVALUATION ##\n",
        "\n",
        "percorso_file = 'VALIDATION.csv'\n",
        "exact_times = extract_true_intervals(file_path=percorso_file)\n",
        "length = len(exact_times)\n",
        "split_point = round(length * split)\n",
        "\n",
        "########################################################################################################################\n",
        "## ENSEMBLE ##\n",
        "########################################################################################################################\n",
        "\n",
        "# Original JSON file name and backup copy\n",
        "original_json_filename = 'model_0.json'\n",
        "backup_json_filename = 'model_ensemble.json'\n",
        "\n",
        "# Read content from the original JSON file\n",
        "with open(original_json_filename, 'r') as original_file:\n",
        "    data = json.load(original_file)\n",
        "\n",
        "# Copy data to a new dictionary\n",
        "backup_data = data.copy()\n",
        "\n",
        "# Check if there are at least \"split_point\" entries in 'results'\n",
        "if len(backup_data['results']) > split_point:\n",
        "    # Remove the first \"split_point\" entries from 'results'\n",
        "    backup_data['results'] = backup_data['results'][split_point:]\n",
        "\n",
        "    # Overwrite the JSON file with updated data\n",
        "    with open(backup_json_filename, 'w') as backup_file:\n",
        "        json.dump(backup_data, backup_file, indent=4)\n",
        "        print(f\"First {split_point} entries successfully removed from 'results'.\")\n",
        "\n",
        "    ########################################################################################################################\n",
        "    ## OVERWRITING THE REMAINING ENTRIES WITH THOSE PREDICTED BY THE ENSEMBLE ##\n",
        "\n",
        "    # Load data from the CSV file\n",
        "    csv_filename = 'predictions.csv'  # Replace with the actual name of your CSV file\n",
        "\n",
        "\n",
        "    # Function to convert a string '[x, y]' into a list of floats [x, y]\n",
        "\n",
        "    def string_to_list(s):\n",
        "        return [float(num) for num in s.strip('[]').split(',')]\n",
        "\n",
        "\n",
        "    csv_data = []\n",
        "    with open(csv_filename, 'r', newline='') as csvfile:\n",
        "        reader = csv.reader(csvfile)\n",
        "\n",
        "        # Skip the first row (column headers)\n",
        "        next(reader)  # This step skips the first row\n",
        "\n",
        "        for row in reader:\n",
        "            csv_data.append([string_to_list(item) for item in row])\n",
        "\n",
        "    with open(backup_json_filename, 'r') as jsonfile:\n",
        "        backup_data = json.load(jsonfile)\n",
        "\n",
        "    # Check if there are enough rows in the CSV to update all 'predicted_times' sections\n",
        "    num_csv_rows = len(csv_data)\n",
        "    num_results = len(backup_data['results'])\n",
        "\n",
        "    if num_csv_rows < num_results:\n",
        "        print(\n",
        "            f\"Warning: The number of rows in the CSV ({num_csv_rows}) is less than the number of 'results' sections to update ({num_results}).\")\n",
        "        print(\"Operation aborted.\")\n",
        "    else:\n",
        "        # Sequentially update the 'predicted_times' sections of 'results'\n",
        "        for i in range(num_results):\n",
        "            backup_data['results'][i]['predicted_times'] = csv_data[i]\n",
        "\n",
        "        # Overwrite the JSON file with updated data\n",
        "        with open(backup_json_filename, 'w') as jsonfile:\n",
        "            json.dump(backup_data, jsonfile, indent=4)\n",
        "            print(\n",
        "                f\"Update complete. The first {num_results} 'predicted_times' sections have been successfully updated.\")\n",
        "else:\n",
        "    print(\"Not enough items to remove.\")\n",
        "\n",
        "########################################################################################################################\n",
        "## BEST ##\n",
        "########################################################################################################################\n",
        "\n",
        "# Original JSON file name and backup copy\n",
        "original_json_filename = 'model_0.json'\n",
        "backup_json_filename = 'model_best.json'\n",
        "\n",
        "# Read content from the original JSON file\n",
        "with open(original_json_filename, 'r') as original_file:\n",
        "    data = json.load(original_file)\n",
        "\n",
        "# Copy data to a new dictionary\n",
        "backup_data = data.copy()\n",
        "\n",
        "# Check if there are at least \"split_point\" entries in 'results'\n",
        "if len(backup_data['results']) > split_point:\n",
        "    # Remove the first \"split_point\" entries from 'results'\n",
        "    backup_data['results'] = backup_data['results'][split_point:]\n",
        "\n",
        "    # Overwrite the JSON file with updated data\n",
        "    with open(backup_json_filename, 'w') as backup_file:\n",
        "        json.dump(backup_data, backup_file, indent=4)\n",
        "        print(f\"First {split_point} entries successfully removed from 'results'.\")\n",
        "\n",
        "    ########################################################################################################################\n",
        "    ## OVERWRITING THE REMAINING ENTRIES WITH THOSE PREDICTED BY THE ENSEMBLE ##\n",
        "\n",
        "    # Load data from the CSV file\n",
        "    csv_filename = 'predictions_best.csv'  # Replace with the actual name of your CSV file\n",
        "\n",
        "    csv_data = []\n",
        "    with open(csv_filename, 'r', newline='') as csvfile:\n",
        "        reader = csv.reader(csvfile)\n",
        "\n",
        "        # Skip the first row (column headers)\n",
        "        next(reader)  # This step skips the first row\n",
        "\n",
        "        for row in reader:\n",
        "            csv_data.append([string_to_list(item) for item in row])\n",
        "\n",
        "    with open(backup_json_filename, 'r') as jsonfile:\n",
        "        backup_data = json.load(jsonfile)\n",
        "\n",
        "    # Check if there are enough rows in the CSV to update all 'predicted_times' sections\n",
        "    num_csv_rows = len(csv_data)\n",
        "    num_results = len(backup_data['results'])\n",
        "\n",
        "    if num_csv_rows < num_results:\n",
        "        print(\n",
        "            f\"Warning: The number of rows in the CSV ({num_csv_rows}) is less than the number of 'results' sections to update ({num_results}).\")\n",
        "        print(\"Operation aborted.\")\n",
        "    else:\n",
        "        # Sequentially update the 'predicted_times' sections of 'results'\n",
        "        for i in range(num_results):\n",
        "            backup_data['results'][i]['predicted_times'] = csv_data[i]\n",
        "\n",
        "        # Overwrite the JSON file with updated data\n",
        "        with open(backup_json_filename, 'w') as jsonfile:\n",
        "            json.dump(backup_data, jsonfile, indent=4)\n",
        "            print(\n",
        "                f\"Update complete. The first {num_results} 'predicted_times' sections have been successfully updated.\")\n",
        "else:\n",
        "    print(\"Not enough items to remove.\")\n"
      ],
      "metadata": {
        "id": "kRvotz7gcTP9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
